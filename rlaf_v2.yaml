name: RLAF Combined Policy and Action Selection
description: Returns top 3 actions based on probability and a boolean to pierce or not, considering initial run or policy update.
# inputs:
#   - name: pierced_rewards
#     type: String
#   - name: baseline_reward
#     type: Float
outputs:
  - name: pierce_or_not
    type: Boolean
  - name: top_3_actions
    type: String
implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        python3 -m pip install --quiet torch numpy || \
        python3 -m pip install --quiet torch numpy --user
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse, torch, json, os, requests
        import numpy as np

        parser = argparse.ArgumentParser()
        parser.add_argument('--pierced_rewards', type=str, required=True)
        parser.add_argument('--baseline_reward', type=float, required=True)
        parser.add_argument('--pierce_or_not', type=str, required=True)
        parser.add_argument('--top_3_actions', type=str, required=True)
        args = parser.parse_args()

        # Ensure output directories exist
        os.makedirs(os.path.dirname(args.pierce_or_not), exist_ok=True)
        os.makedirs(os.path.dirname(args.top_3_actions), exist_ok=True)

        # Functions to fetch data from the database (from sus2.py)
        def get_access_token():
            login_url = "https://ig.aidtaas.com/mobius-iam-service/v1.0/login"
            headers = {
                "content-type": "application/json",
                "mask": "false"
            }
            payload = {
                "userName": "aidtaas@gaiansolutions.com",
                "password": "Gaian@123",
                "productId": "c2255be4-ddf6-449e-a1e0-b4f7f9a2b636",
                "requestType": "TENANT"
            }
            response = requests.post(login_url, headers=headers, json=payload)
            response.raise_for_status() # Raise an exception for HTTP errors
            return response.json()["accessToken"]

        def get_instances(access_token):
            instances_url = "https://ig.aidtaas.com/pi-entity-instances-service/v3.0/schemas/685a9dcd08232436a767c98a/instances/list"
            headers = {
                "Authorization": f"Bearer {access_token}",
                "Content-Type": "application/json"
            }
            payload = {
                "dbType": "TIDB",
                "ownedOnly": True,
                "filter": {
                    "id": "1"
                }
            }
            response = requests.post(instances_url, headers=headers, json=payload)
            response.raise_for_status() # Raise an exception for HTTP errors
            return response.json()

        # Fetch data
        token = get_access_token()
        db_data = get_instances(token)
        
        # Extract actions and initial logits from the database data
        # Assuming the structure is db_data["content"][0]["rlaf_config"]["actions"]
        # And each action has a 'score' field which is the logit
        fetched_actions = db_data["content"][0]["rlaf_config"]["actions"]
        
        action_space_list = []
        initial_logits_list = []
        for action_item in fetched_actions:
            # Assuming 'lr' is the learning rate and 'score' is the logit
            action_space_list.append(action_item)
            initial_logits_list.append(action_item["score"])

        current_logits = torch.tensor(initial_logits_list, dtype=torch.float32, requires_grad=True)
        
        pierced_rewards_str = args.pierced_rewards
        baseline = args.baseline_reward
        
        pierce_decision = True # Default to true for initial run or if baseline not met
        
        if pierced_rewards_str == "-1":
            # Initial run: Do not update policy, just get top 3 actions from initial logits
            pass # current_logits is already set from logits_in
        else:
            # Subsequent run: Update policy based on pierced rewards
            pierced_rewards_dict = json.loads(pierced_rewards_str)
            
            # Create a mapping from action name to index
            action_name_to_idx = {action_data["learning_rate"]: idx for idx, action_data in enumerate(action_space_list)}

            # Check if any of the pierced rewards reached the baseline
            for action_name_key, reward_val in pierced_rewards_dict.items():
                if reward_val >= baseline:
                    pierce_decision = False
                    break
            
            # Policy update logic (REINFORCE)
            optimizer = torch.optim.Adam([current_logits], lr=0.05)

            for action_name_key, reward_val in pierced_rewards_dict.items():
                action_idx = action_name_to_idx.get(float(action_name_key)) # Convert key back to float for lookup
                if action_idx is None:
                    print(f"Warning: Action name '{action_name_key}' not found in action space. Skipping.")
                    continue
                
                # Calculate log_prob for the specific action from current_logits
                probs = torch.softmax(current_logits, dim=0)
                dist = torch.distributions.Categorical(probs)
                log_prob_tensor = dist.log_prob(torch.tensor(action_idx))
                
                loss = -log_prob_tensor * (reward_val - baseline)
                
                optimizer.zero_grad() # Clear gradients for this specific update
                loss.backward()       # Compute gradients
                optimizer.step()      # Apply update
                
                # Detach logits after each step to prevent graph accumulation across loop iterations
                current_logits = current_logits.detach().requires_grad_(True)
 
             # After policy update, update scores in the database
             # Construct the patch requests for each action's score
             patch_requests = []
             updated_logits_list = current_logits.tolist() # Convert tensor to list for JSON serialization
             for idx, action_item in enumerate(fetched_actions):
                 # Assuming the path to update score is /rlaf_config/actions/{index}/score
                 patch_requests.append({
                     "operation": "REPLACE",
                     "path": f"/rlaf_config/actions/{idx}/score",
                     "value": updated_logits_list[idx]
                 })
             
             update_url = "https://ig.aidtaas.com/pi-entity-instances-service/v2.0/schemas/685a9dcd08232436a767c98a/instances"
             update_headers = {
                 "Authorization": f"Bearer {token}", # Use the same token fetched earlier
                 "Content-Type": "application/json"
             }
             update_payload = {
                 "dbType": "TIDB",
                 "conditionalFilter": {
                     "conditions": [
                         {
                             "field": "id",
                             "operator": "EQUAL",
                             "value": "1" # Assuming the ID is always 1
                         }
                     ]
                 },
                 "partialUpdateRequests": [
                     {
                         "patch": patch_requests
                     }
                 ]
             }
             
             try:
                 update_response = requests.patch(update_url, headers=update_headers, json=update_payload)
                 update_response.raise_for_status()
                 print(f"Successfully updated scores in DB: {update_response.json()}")
             except requests.exceptions.RequestException as e:
                 print(f"Error updating scores in DB: {e}")
 
         # Get top 3 actions based on current (or updated) logits
         probs = torch.softmax(current_logits, dim=0)
        
        # Get top 3 actions by probability
        top_probs, top_indices = torch.topk(probs, k=3)
        
        top_actions_list = []
        for i in range(3):
            action_idx = top_indices[i].item()
            action_data = action_space_list[action_idx] if action_idx < len(action_space_list) else {"learning_rate": "unknown"}
            action_with_prob = action_data.copy()
            if "score" in action_with_prob:
                del action_with_prob["score"]
            action_with_prob["probability"] = round(top_probs[i].item(), 4)
            top_actions_list.append(action_with_prob)

        # Write outputs
        with open(args.pierce_or_not, 'w') as f:
            f.write(str(pierce_decision).lower()) # Write as 'true' or 'false'
        with open(args.top_3_actions, 'w') as f:
            f.write(json.dumps(top_actions_list))

    args:
      # - --pierced_rewards
      # - {inputPath: pierced_rewards}
      # - --baseline_reward
      # - {inputPath: baseline_reward}
      - --pierce_or_not
      - {outputPath: pierce_or_not}
      - --top_3_actions
      - {outputPath: top_3_actions}